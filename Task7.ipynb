{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber\\anaconda3\\envs\\nullclass1\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading Task7\\preprocessed_train_set.csv: Error tokenizing data. C error: Expected 28 fields in line 23, saw 70\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber\\anaconda3\\envs\\nullclass1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "import pandas as pd\n",
    "import os\n",
    "import language_tool_python\n",
    "import spacy\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize the grammar checking tool and NLP model\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Directory where datasets are stored\n",
    "data_dir = \"Task7\"\n",
    "\n",
    "# Load datasets\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "preprocessed_train_set = load_data(os.path.join(data_dir, 'preprocessed_train_set.csv'))\n",
    "preprocessed_valid_set = load_data(os.path.join(data_dir, 'preprocessed_valid_set.csv'))\n",
    "scored_train_set = load_data(os.path.join(data_dir, 'scored_train_set.csv'))\n",
    "scored_valid_set = load_data(os.path.join(data_dir, 'scored_valid_set.csv'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_essay(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.lower().strip()\n",
    "    return ''\n",
    "\n",
    "# Function to check grammatical mistakes\n",
    "def check_grammar(essay):\n",
    "    matches = tool.check(essay)\n",
    "    num_errors = len(matches)\n",
    "    return num_errors\n",
    "\n",
    "# Function to calculate the number of lines in the essay\n",
    "def count_lines(essay):\n",
    "    lines = essay.splitlines()  # Split the text by actual line breaks\n",
    "    num_lines = len([line for line in lines if line.strip()])  # Count non-empty lines\n",
    "    return num_lines\n",
    "\n",
    "# Function to extract main concept of the essay using Named Entity Recognition (NER)\n",
    "def extract_concept(essay):\n",
    "    doc = nlp(essay)\n",
    "    # Extract entities or keywords as the main concept (e.g., a named entity like an organization, person, etc.)\n",
    "    concepts = [ent.text for ent in doc.ents if ent.label_ in ['ORG', 'PERSON', 'GPE', 'NORP', 'PRODUCT', 'EVENT']]\n",
    "    return concepts if concepts else None\n",
    "\n",
    "# Function to check if the entire essay relates to the main concept\n",
    "def is_essay_relevant_to_concept(essay, concepts):\n",
    "    if not concepts:\n",
    "        return True  # If no concept was identified, we cannot penalize it\n",
    "\n",
    "    doc = nlp(essay)\n",
    "    matches = 0\n",
    "    for concept in concepts:\n",
    "        if concept.lower() in doc.text.lower():\n",
    "            matches += 1\n",
    "\n",
    "    # If less than half of the essay matches the main concept, we penalize\n",
    "    total_sentences = len(list(doc.sents))\n",
    "    if matches < total_sentences // 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Function to compare essays with preprocessed datasets and provide a score\n",
    "def get_score_from_dataset(essay):\n",
    "    # Preprocess the input essay for comparison\n",
    "    processed_essay = preprocess_essay(essay)\n",
    "    \n",
    "    # Check if the essay exists in preprocessed_train_set or preprocessed_valid_set\n",
    "    if preprocessed_train_set is not None and processed_essay in preprocessed_train_set['essay'].values:\n",
    "        matched_row = preprocessed_train_set[preprocessed_train_set['essay'] == processed_essay]\n",
    "        return int(matched_row['score'].values[0])\n",
    "    \n",
    "    if preprocessed_valid_set is not None and processed_essay in preprocessed_valid_set['essay'].values:\n",
    "        matched_row = preprocessed_valid_set[preprocessed_valid_set['essay'] == processed_essay]\n",
    "        return int(matched_row['score'].values[0])\n",
    "\n",
    "    # Default score of 3 if no match found\n",
    "    return None\n",
    "\n",
    "# Scoring function\n",
    "def score_essay(essay):\n",
    "    essay = preprocess_essay(essay)\n",
    "    \n",
    "    # Try to fetch a score from the preprocessed datasets\n",
    "    dataset_score = get_score_from_dataset(essay)\n",
    "    if dataset_score is not None:\n",
    "        return dataset_score\n",
    "    \n",
    "    # Get the number of lines\n",
    "    num_lines = count_lines(essay)\n",
    "    \n",
    "    # Get the number of grammatical errors\n",
    "    num_grammar_errors = check_grammar(essay)\n",
    "\n",
    "    # Debugging outputs\n",
    "    print(f\"Processed Essay: {essay}\")\n",
    "    print(f\"Number of lines: {num_lines}\")\n",
    "    print(f\"Number of grammatical errors: {num_grammar_errors}\")\n",
    "    \n",
    "    # Base score initialization\n",
    "    score = 3  # Start with a default score of 3\n",
    "\n",
    "    # Adjust score based on the number of lines\n",
    "    if num_lines >= 10:\n",
    "        score += 2\n",
    "    elif num_lines >= 5:\n",
    "        score += 1\n",
    "    else:\n",
    "        score -= 1  # Penalize for short essays\n",
    "\n",
    "    # Adjust score based on grammatical mistakes\n",
    "    if num_grammar_errors > 10:\n",
    "        score -= 2\n",
    "    elif num_grammar_errors > 5:\n",
    "        score -= 1\n",
    "    else:\n",
    "        score += 1  # Reward fewer grammar mistakes\n",
    "\n",
    "    # Check if the essay is relevant to the identified concept\n",
    "    concepts = extract_concept(essay)\n",
    "    is_relevant = is_essay_relevant_to_concept(essay, concepts)\n",
    "    \n",
    "    if not is_relevant:\n",
    "        score -= 3  # Penalize for being off-topic\n",
    "\n",
    "    # Ensure score is between 1 and 6\n",
    "    score = max(1, min(score, 6))\n",
    "\n",
    "    print(f\"Final Score: {score}\")  # Debugging: check the final score\n",
    "    return score\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('Task7.html')\n",
    "\n",
    "@app.route('/submit', methods=['POST'])\n",
    "def submit():\n",
    "    essay = request.form.get('essay')\n",
    "    if not essay:\n",
    "        return jsonify({'error': 'No essay provided'}), 400\n",
    "    \n",
    "    try:\n",
    "        score = score_essay(essay)\n",
    "        return jsonify({'score': score})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nullclass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
